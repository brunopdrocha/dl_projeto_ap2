{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd23e69",
   "metadata": {},
   "source": [
    "# Etiquetamento Autônomo de Perguntas do StackOverflow com Deep Learning\n",
    "\n",
    "- Bruno Pilão\n",
    "- Maria Mello\n",
    "- Larissa Nobrega\n",
    "- Fernanda Moyses \n",
    "\n",
    "\n",
    "O objetivo do trabalho é desenvolver um modelo Deep Learning para o etiquetamento autônomo (*multi-label classification*) de perguntas do StackOverflow.\n",
    "\n",
    "CONJUNTO DE DADOS\n",
    "\n",
    "A base de dados a ser utilizada é a StackLite, disponível em https://github.com/dgrtwo/StackLite.\n",
    "\n",
    "A StackLite é uma versão simplificada e pré-processada de uma parte dos dados do Stack Overflow, contendo perguntas e suas tags associadas.\n",
    "\n",
    "Embora o repositório possa conter outros arquivos, o foco será nos dados que permitem mapear perguntas (corpo e/ou título) para suas tags.\n",
    "\n",
    "Obs.: Uma única pergunta pode ter múltiplas tags, o que a torna um problema de classificação multilabel. Pense em uma forma de priorizar uma das tags para simplificar o problema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007f45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MultiLabelBinarizer,StandardScaler,LabelEncoder\n",
    "from sklearn.metrics import classification_report,hamming_loss\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7601f077",
   "metadata": {},
   "source": [
    "## Análise breve dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a982740",
   "metadata": {},
   "source": [
    "### Dataset Auxiliar \n",
    "\n",
    "Este dataset constitui um dicionário que mapeia cada questão gerada no Stack Overflow às suas respectivas categorias temáticas. O conjunto de dados auxiliar será utilizado para realizar uma análise prévia com o objetivo de avaliar e classificar os tipos de respostas associadas a cada pergunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c5eb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>winforms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>type-conversion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>decimal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id              Tag\n",
       "0   1             data\n",
       "1   4               c#\n",
       "2   4         winforms\n",
       "3   4  type-conversion\n",
       "4   4          decimal"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importação dataset tags\n",
    "df_tags = pd.read_csv('data\\question_tags.csv.gz',compression='gzip')\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414cc4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52224835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validandop quantidade de itens na datable\n",
    "len(df_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d0613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de itens por ID\n",
      "1 ['data']\n",
      "2 []\n",
      "3 []\n",
      "4 ['c#' 'winforms' 'type-conversion' 'decimal' 'opacity']\n",
      "5 []\n",
      "6 ['html' 'css' 'css3' 'internet-explorer-7']\n",
      "7 []\n",
      "8 ['c#' 'code-generation' 'j#' 'visualj#']\n",
      "9 ['c#' '.net' 'datetime']\n",
      "10 []\n"
     ]
    }
   ],
   "source": [
    "#Validando tipos de tag\n",
    "print(\"Quantidade de itens por ID\")\n",
    "for i in range(10):\n",
    "    print(i+1,df_tags[df_tags['Id'] == i+1]['Tag'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f6b90",
   "metadata": {},
   "source": [
    "Observamos que as tags não possuem um ordem sequencial e podem conter um ou multiplos valores dentro de um ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a57099f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grouped criado: 17,763,486 IDs únicos\n"
     ]
    }
   ],
   "source": [
    "# GroupBy simples: ID → lista de tags\n",
    "grouped_mini = df_tags.groupby('Id')['Tag'].apply(list).reset_index()\n",
    "\n",
    "print(f\"✅ Grouped criado: {len(grouped_mini):,} IDs únicos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e594a5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Backup CSV: stackoverflow_grouped_tags.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Salvar em CSV ()\n",
    "grouped_mini.to_csv('stackoverflow_grouped_tags.csv', index=False)\n",
    "print(\"✅ Backup CSV: stackoverflow_grouped_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "711ab5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprimir CSV (reduz ~80%)\n",
    "df = pd.read_csv('stackoverflow_grouped_tags.csv')\n",
    "df.to_csv('stackoverflow_grouped_tags.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0082c8b",
   "metadata": {},
   "source": [
    "Com isso avaliamos que este dataset serve como um \"Dicionário\" para identificar o tipo de pergunta que o usuario realizou no stackoverflow, sendo que uma tg pode contem um ou múltiplos assuntos envolvidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16c0ba",
   "metadata": {},
   "source": [
    "### Dataset Principal\n",
    "\n",
    "O dataset principal consiste em perguntas técnicas geradas por usuários da plataforma Stack Overflow. Este conjunto de dados contém questões formuladas por desenvolvedores e profissionais de tecnologia que buscam soluções para problemas específicos em suas áreas de atuação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb59843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>DeletionDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-31T21:26:37Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-28T00:53:47Z</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-07-31T21:42:52Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>472</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-07-31T22:08:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-07-31T23:33:19Z</td>\n",
       "      <td>2013-06-03T04:00:25Z</td>\n",
       "      <td>2015-02-11T08:26:40Z</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-07-31T23:40:59Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id          CreationDate            ClosedDate          DeletionDate  \\\n",
       "0   1  2008-07-31T21:26:37Z                   NaN  2011-03-28T00:53:47Z   \n",
       "1   4  2008-07-31T21:42:52Z                   NaN                   NaN   \n",
       "2   6  2008-07-31T22:08:08Z                   NaN                   NaN   \n",
       "3   8  2008-07-31T23:33:19Z  2013-06-03T04:00:25Z  2015-02-11T08:26:40Z   \n",
       "4   9  2008-07-31T23:40:59Z                   NaN                   NaN   \n",
       "\n",
       "   Score  OwnerUserId  AnswerCount  \n",
       "0      1          NaN          0.0  \n",
       "1    472          8.0         13.0  \n",
       "2    210          9.0          5.0  \n",
       "3     42          NaN          8.0  \n",
       "4   1452          1.0         58.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importação dataset questions\n",
    "df_questions = pd.read_csv('data\\questions.csv.gz',compression='gzip')\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d78a03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17763486"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantiade de itens df_qustions\n",
    "\n",
    "len(df_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dfcc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17763486 entries, 0 to 17763485\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Id            int64  \n",
      " 1   CreationDate  object \n",
      " 2   ClosedDate    object \n",
      " 3   DeletionDate  object \n",
      " 4   Score         int64  \n",
      " 5   OwnerUserId   float64\n",
      " 6   AnswerCount   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 948.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Validar tipos de variáveis ao nosso dataset\n",
    "df_questions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a50c9f",
   "metadata": {},
   "source": [
    "## Merge Datasets\n",
    "\n",
    "Vamos agrupar nosso dataset para melhor perfomace no treinamento do nosso modelo para predição de tag do stack overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307a3144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset final: (17763486, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>DeletionDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-31T21:26:37Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-28T00:53:47Z</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-07-31T21:42:52Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>472</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[c#, winforms, type-conversion, decimal, opacity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-07-31T22:08:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[html, css, css3, internet-explorer-7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-07-31T23:33:19Z</td>\n",
       "      <td>2013-06-03T04:00:25Z</td>\n",
       "      <td>2015-02-11T08:26:40Z</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[c#, code-generation, j#, visualj#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-07-31T23:40:59Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[c#, .net, datetime]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id          CreationDate            ClosedDate          DeletionDate  \\\n",
       "0   1  2008-07-31T21:26:37Z                   NaN  2011-03-28T00:53:47Z   \n",
       "1   4  2008-07-31T21:42:52Z                   NaN                   NaN   \n",
       "2   6  2008-07-31T22:08:08Z                   NaN                   NaN   \n",
       "3   8  2008-07-31T23:33:19Z  2013-06-03T04:00:25Z  2015-02-11T08:26:40Z   \n",
       "4   9  2008-07-31T23:40:59Z                   NaN                   NaN   \n",
       "\n",
       "   Score  OwnerUserId  AnswerCount  \\\n",
       "0      1          NaN          0.0   \n",
       "1    472          8.0         13.0   \n",
       "2    210          9.0          5.0   \n",
       "3     42          NaN          8.0   \n",
       "4   1452          1.0         58.0   \n",
       "\n",
       "                                                 Tag  \n",
       "0                                             [data]  \n",
       "1  [c#, winforms, type-conversion, decimal, opacity]  \n",
       "2             [html, css, css3, internet-explorer-7]  \n",
       "3                [c#, code-generation, j#, visualj#]  \n",
       "4                               [c#, .net, datetime]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos realizar um merge de nosso dataset \n",
    "df = df_questions.merge(grouped_mini,on='Id',how='inner')\n",
    "\n",
    "# Verificar resultado\n",
    "print(f\"Dataset final: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adafc683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para datetime\n",
    "df['CreationDate'] = pd.to_datetime(df['CreationDate'])\n",
    "df['Year'] = df['CreationDate'].dt.year\n",
    "df['Month'] = df['CreationDate'].dt.month  \n",
    "df['Day'] = df['CreationDate'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45550dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>DeletionDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-31 21:26:37+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-03-28T00:53:47Z</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[data]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-07-31 21:42:52+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>472</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[c#, winforms, type-conversion, decimal, opacity]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2008-07-31 22:08:08+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[html, css, css3, internet-explorer-7]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>2008-07-31 23:33:19+00:00</td>\n",
       "      <td>2013-06-03T04:00:25Z</td>\n",
       "      <td>2015-02-11T08:26:40Z</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[c#, code-generation, j#, visualj#]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2008-07-31 23:40:59+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[c#, .net, datetime]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id              CreationDate            ClosedDate          DeletionDate  \\\n",
       "0   1 2008-07-31 21:26:37+00:00                   NaN  2011-03-28T00:53:47Z   \n",
       "1   4 2008-07-31 21:42:52+00:00                   NaN                   NaN   \n",
       "2   6 2008-07-31 22:08:08+00:00                   NaN                   NaN   \n",
       "3   8 2008-07-31 23:33:19+00:00  2013-06-03T04:00:25Z  2015-02-11T08:26:40Z   \n",
       "4   9 2008-07-31 23:40:59+00:00                   NaN                   NaN   \n",
       "\n",
       "   Score  OwnerUserId  AnswerCount  \\\n",
       "0      1          NaN          0.0   \n",
       "1    472          8.0         13.0   \n",
       "2    210          9.0          5.0   \n",
       "3     42          NaN          8.0   \n",
       "4   1452          1.0         58.0   \n",
       "\n",
       "                                                 Tag  Year  Month  Day  \n",
       "0                                             [data]  2008      7   31  \n",
       "1  [c#, winforms, type-conversion, decimal, opacity]  2008      7   31  \n",
       "2             [html, css, css3, internet-explorer-7]  2008      7   31  \n",
       "3                [c#, code-generation, j#, visualj#]  2008      7   31  \n",
       "4                               [c#, .net, datetime]  2008      7   31  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb87e684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[data]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[c#, winforms, type-conversion, decimal, opacity]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[html, css, css3, internet-explorer-7]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[c#, code-generation, j#, visualj#]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[c#, .net, datetime]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score  OwnerUserId  AnswerCount  \\\n",
       "0      1          NaN          0.0   \n",
       "1    472          8.0         13.0   \n",
       "2    210          9.0          5.0   \n",
       "3     42          NaN          8.0   \n",
       "4   1452          1.0         58.0   \n",
       "\n",
       "                                                 Tag  Year  Month  Day  \n",
       "0                                             [data]  2008      7   31  \n",
       "1  [c#, winforms, type-conversion, decimal, opacity]  2008      7   31  \n",
       "2             [html, css, css3, internet-explorer-7]  2008      7   31  \n",
       "3                [c#, code-generation, j#, visualj#]  2008      7   31  \n",
       "4                               [c#, .net, datetime]  2008      7   31  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo colunas que não são necessarios para nosso treinamento\n",
    "df = df.drop(columns=[\"ClosedDate\",\"DeletionDate\",\"CreationDate\",\"Id\"],axis=1)\n",
    "\n",
    "# Validando DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7994e5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17763486 entries, 0 to 17763485\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   Score        int64  \n",
      " 1   OwnerUserId  float64\n",
      " 2   AnswerCount  float64\n",
      " 3   Tag          object \n",
      " 4   Year         int32  \n",
      " 5   Month        int32  \n",
      " 6   Day          int32  \n",
      "dtypes: float64(2), int32(3), int64(1), object(1)\n",
      "memory usage: 745.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114fa03",
   "metadata": {},
   "source": [
    "Com isso vamos utilizar este dataframe para realizar uma predição com uma frase de texto bruta e acimiliar o tipo de conteudo que estou relatando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41957ee",
   "metadata": {},
   "source": [
    "## Treinamento de Modelo\n",
    "\n",
    "Vamos inicialmente ajustar o nosso treinamento do modelo para que com uma frase de entrada o nosso modelo consiga captar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "774ae907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[data]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>[c#, winforms, type-conversion, decimal, opacity]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[html, css, css3, internet-explorer-7]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[c#, code-generation, j#, visualj#]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>[c#, .net, datetime]</td>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score  OwnerUserId  AnswerCount  \\\n",
       "0      1          NaN          0.0   \n",
       "1    472          8.0         13.0   \n",
       "2    210          9.0          5.0   \n",
       "3     42          NaN          8.0   \n",
       "4   1452          1.0         58.0   \n",
       "\n",
       "                                                 Tag  Year  Month  Day  \n",
       "0                                             [data]  2008      7   31  \n",
       "1  [c#, winforms, type-conversion, decimal, opacity]  2008      7   31  \n",
       "2             [html, css, css3, internet-explorer-7]  2008      7   31  \n",
       "3                [c#, code-generation, j#, visualj#]  2008      7   31  \n",
       "4                               [c#, .net, datetime]  2008      7   31  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d2d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduz para uma amostra da base mantendo a distribuição das tags\n",
    "df_sampled = df.sample(n=50_000, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1146a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Corrigir a coluna de tags\n",
    "def safe_literal_eval(tag_value):\n",
    "    try:\n",
    "        return ast.literal_eval(tag_value)\n",
    "    except:\n",
    "        try:\n",
    "            tag_str = str(tag_value).strip()\n",
    "            if tag_str in ['nan', 'None', '', '[]']:\n",
    "                return []\n",
    "            tag_str = tag_str.strip('[]')\n",
    "            tags = [tag.strip().strip(\"'\").strip('\"') for tag in tag_str.split(',')]\n",
    "            return [tag for tag in tags if tag]\n",
    "        except:\n",
    "            return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "350abc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar e limpar os dados\n",
    "df['Tag'] = df['Tag'].apply(safe_literal_eval)\n",
    "df = df[df['Tag'].map(len) > 0]\n",
    "\n",
    "# Contar frequência de todas as tags\n",
    "all_tags = [tag for tags in df['Tag'] for tag in tags]\n",
    "tag_counts = Counter(all_tags)\n",
    "\n",
    "# Definir o número de tags mais comuns que você quer manter \n",
    "top_tags = set([tag for tag, count in tag_counts.most_common(50)])\n",
    "\n",
    "# Filtrar somente linhas com pelo menos uma tag entre as mais comuns\n",
    "df['Tag'] = df['Tag'].apply(lambda tags: [tag for tag in tags if tag in top_tags])\n",
    "df = df[df['Tag'].map(len) > 0]  # Remover quem ficou com lista vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7387550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: (10814617, 6)\n",
      "Teste: (2703655, 6)\n",
      "Número de classes: 50\n"
     ]
    }
   ],
   "source": [
    "features = [\"Year\", \"Month\", \"Day\", \"Score\", \"OwnerUserId\", \"AnswerCount\"]\n",
    "X = df[features]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['Tag'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f'Treinamento: {X_train.shape}')\n",
    "print(f'Teste: {X_test.shape}')\n",
    "print(f'Número de classes: {len(mlb.classes_)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55599ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAGNÓSTICO DO PROBLEMA ===\n",
      "Treinamento: (10814617, 6)\n",
      "Teste: (2703655, 6)\n",
      "Número de classes: 50\n",
      "✅ Número de classes OK: 50\n",
      "Dataset preparado: (10814617, 6)\n",
      "Labels shape: (10814617, 50)\n",
      "🚀 Iniciando comparação de arquiteturas...\n",
      "=== CRIANDO MODELOS ===\n",
      "Modelo Simples: 26,546 parâmetros\n",
      "Modelo Complexo: 223,018 parâmetros\n",
      "\n",
      "=== TREINANDO CNN SIMPLES ===\n",
      "Epoch 1/20\n",
      "\u001b[1m42245/42245\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 5ms/step - accuracy: 0.0822 - loss: 0.1265 - precision: 0.0338 - recall: 0.0019 - val_accuracy: 0.0844 - val_loss: 0.1202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m17110/42245\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:56\u001b[0m 5ms/step - accuracy: 0.0892 - loss: 0.1209 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 251\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 Iniciando comparação de arquiteturas...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Treinar modelos\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m model_simple, model_complex, history_simple, history_complex, X_test_cnn = \u001b[43mtrain_and_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# Avaliação final\u001b[39;00m\n\u001b[32m    254\u001b[39m metrics_df = evaluate_models_quick(model_simple, model_complex, X_test_cnn, y_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 181\u001b[39m, in \u001b[36mtrain_and_compare\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# Treinar modelo simples\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== TREINANDO CNN SIMPLES ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m history_simple = \u001b[43mmodel_simple\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduzido para testar\u001b[39;49;00m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# Treinar modelo complexo\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== TREINANDO CNN COMPLEXA ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32ms:\\deep learning\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# DIAGNÓSTICO + PREPARAÇÃO DOS DADOS ADAPTADO AO SEU SETUP\n",
    "# ===================================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, hamming_loss, accuracy_score\n",
    "\n",
    "# VERIFICAR PROBLEMA DAS CLASSES\n",
    "print(\"=== DIAGNÓSTICO DO PROBLEMA ===\")\n",
    "print(f'Treinamento: {X_train.shape}')\n",
    "print(f'Teste: {X_test.shape}')\n",
    "print(f'Número de classes: {len(mlb.classes_)}')\n",
    "\n",
    "# Se muitas classes, vamos reduzir\n",
    "if len(mlb.classes_) > 100:\n",
    "    print(f\"⚠️  MUITAS CLASSES ({len(mlb.classes_)})! Reduzindo para top 50...\")\n",
    "    \n",
    "    # Contar frequência das labels\n",
    "    label_counts = y_train.sum(axis=0)\n",
    "    top_50_indices = np.argsort(label_counts)[-50:][::-1]\n",
    "    \n",
    "    # Filtrar apenas top 50\n",
    "    y_train = y_train[:, top_50_indices]\n",
    "    y_test = y_test[:, top_50_indices]\n",
    "    \n",
    "    # Atualizar classes\n",
    "    top_classes = [mlb.classes_[i] for i in top_50_indices]\n",
    "    print(f\"Reduzido para {y_train.shape[1]} classes\")\n",
    "    print(f\"Top 10 classes: {top_classes[:10]}\")\n",
    "else:\n",
    "    print(f\"✅ Número de classes OK: {len(mlb.classes_)}\")\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.fillna(0))\n",
    "X_test_scaled = scaler.transform(X_test.fillna(0))\n",
    "\n",
    "print(f\"Dataset preparado: {X_train_scaled.shape}\")\n",
    "print(f\"Labels shape: {y_train.shape}\")\n",
    "\n",
    "# ===================================================================\n",
    "# ARQUITETURA 1: CNN SIMPLES\n",
    "# ===================================================================\n",
    "\n",
    "def create_simple_cnn():\n",
    "    \"\"\"CNN Simples para baseline\"\"\"\n",
    "    \n",
    "    # Reshape para CNN: (samples, features, channels)\n",
    "    X_train_cnn = X_train_scaled.reshape(-1, 6, 1)\n",
    "    X_test_cnn = X_test_scaled.reshape(-1, 6, 1)\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(6, 1)),\n",
    "        \n",
    "        # CNN Simples\n",
    "        tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Global pooling\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        \n",
    "        # Dense layers\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Output multilabel - USAR TAMANHO CORRETO\n",
    "        tf.keras.layers.Dense(y_train.shape[1], activation='sigmoid')\n",
    "    ], name='CNN_Simples')\n",
    "    \n",
    "    return model, X_train_cnn, X_test_cnn\n",
    "\n",
    "# ===================================================================\n",
    "# ARQUITETURA 2: CNN COMPLEXA (INCEPTION-LIKE)\n",
    "# ===================================================================\n",
    "\n",
    "def inception_block_1d(x, f1, f3_red, f3, f5_red, f5, pool_proj):\n",
    "    \"\"\"Bloco Inception simplificado\"\"\"\n",
    "    # Branch 1: 1x1\n",
    "    branch1 = tf.keras.layers.Conv1D(f1, 1, activation='relu', padding='same')(x)\n",
    "    \n",
    "    # Branch 2: 1x1 -> 3x3\n",
    "    branch2 = tf.keras.layers.Conv1D(f3_red, 1, activation='relu', padding='same')(x)\n",
    "    branch2 = tf.keras.layers.Conv1D(f3, 3, activation='relu', padding='same')(branch2)\n",
    "    \n",
    "    # Branch 3: 1x1 -> 5x5 (substituído por duas 3x3)\n",
    "    branch3 = tf.keras.layers.Conv1D(f5_red, 1, activation='relu', padding='same')(x)\n",
    "    branch3 = tf.keras.layers.Conv1D(f5, 3, activation='relu', padding='same')(branch3)\n",
    "    \n",
    "    # Branch 4: pool -> 1x1\n",
    "    branch4 = tf.keras.layers.MaxPooling1D(3, strides=1, padding='same')(x)\n",
    "    branch4 = tf.keras.layers.Conv1D(pool_proj, 1, activation='relu', padding='same')(branch4)\n",
    "    \n",
    "    return tf.keras.layers.Concatenate()([branch1, branch2, branch3, branch4])\n",
    "\n",
    "def create_complex_cnn():\n",
    "    \"\"\"CNN Complexa com Inception Blocks\"\"\"\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(6, 1))\n",
    "    \n",
    "    # Entrada\n",
    "    x = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Inception blocks\n",
    "    x = inception_block_1d(x, 16, 24, 32, 8, 16, 8)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = inception_block_1d(x, 32, 48, 64, 16, 32, 16)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = inception_block_1d(x, 64, 96, 128, 32, 64, 32)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Global pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    # Dense layers mais robustas\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Output - USAR TAMANHO CORRETO\n",
    "    outputs = tf.keras.layers.Dense(y_train.shape[1], activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='CNN_Complexa_Inception')\n",
    "    return model\n",
    "\n",
    "# ===================================================================\n",
    "# TREINAMENTO E COMPARAÇÃO\n",
    "# ===================================================================\n",
    "\n",
    "def train_and_compare():\n",
    "    \"\"\"Treina ambos modelos e compara performance\"\"\"\n",
    "    \n",
    "    # Criar modelos\n",
    "    print(\"=== CRIANDO MODELOS ===\")\n",
    "    model_simple, X_train_cnn, X_test_cnn = create_simple_cnn()\n",
    "    model_complex = create_complex_cnn()\n",
    "    \n",
    "    # Compilar ambos\n",
    "    compile_config = {\n",
    "        'optimizer': 'adam',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': ['accuracy', 'precision', 'recall']\n",
    "    }\n",
    "    \n",
    "    model_simple.compile(**compile_config)\n",
    "    model_complex.compile(**compile_config)\n",
    "    \n",
    "    print(f\"Modelo Simples: {model_simple.count_params():,} parâmetros\")\n",
    "    print(f\"Modelo Complexo: {model_complex.count_params():,} parâmetros\")\n",
    "    \n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    ]\n",
    "    \n",
    "    # Treinar modelo simples\n",
    "    print(\"\\n=== TREINANDO CNN SIMPLES ===\")\n",
    "    history_simple = model_simple.fit(\n",
    "        X_train_cnn, y_train,\n",
    "        validation_data=(X_test_cnn, y_test),\n",
    "        epochs=20,  # Reduzido para testar\n",
    "        batch_size=256,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Treinar modelo complexo\n",
    "    print(\"\\n=== TREINANDO CNN COMPLEXA ===\")\n",
    "    history_complex = model_complex.fit(\n",
    "        X_train_cnn, y_train,\n",
    "        validation_data=(X_test_cnn, y_test),\n",
    "        epochs=20,  # Reduzido para testar\n",
    "        batch_size=256,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model_simple, model_complex, history_simple, history_complex, X_test_cnn\n",
    "\n",
    "# ===================================================================\n",
    "# AVALIAÇÃO RÁPIDA\n",
    "# ===================================================================\n",
    "\n",
    "def evaluate_models_quick(model_simple, model_complex, X_test_cnn, y_test):\n",
    "    \"\"\"Avaliação rápida dos modelos\"\"\"\n",
    "    \n",
    "    print(\"=== AVALIAÇÃO FINAL DOS MODELOS ===\")\n",
    "    \n",
    "    # Predições\n",
    "    y_pred_simple = model_simple.predict(X_test_cnn)\n",
    "    y_pred_complex = model_complex.predict(X_test_cnn)\n",
    "    \n",
    "    # Converter para binário (threshold=0.5)\n",
    "    y_pred_simple_bin = (y_pred_simple > 0.5).astype(int)\n",
    "    y_pred_complex_bin = (y_pred_complex > 0.5).astype(int)\n",
    "    \n",
    "    # Métricas\n",
    "    metrics = {\n",
    "        'CNN Simples': {\n",
    "            'Hamming Loss': hamming_loss(y_test, y_pred_simple_bin),\n",
    "            'F1-Score (micro)': f1_score(y_test, y_pred_simple_bin, average='micro'),\n",
    "            'F1-Score (macro)': f1_score(y_test, y_pred_simple_bin, average='macro'),\n",
    "            'Accuracy': accuracy_score(y_test, y_pred_simple_bin)\n",
    "        },\n",
    "        'CNN Complexa': {\n",
    "            'Hamming Loss': hamming_loss(y_test, y_pred_complex_bin),\n",
    "            'F1-Score (micro)': f1_score(y_test, y_pred_complex_bin, average='micro'),\n",
    "            'F1-Score (macro)': f1_score(y_test, y_pred_complex_bin, average='macro'),\n",
    "            'Accuracy': accuracy_score(y_test, y_pred_complex_bin)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Tabela comparativa\n",
    "    import pandas as pd\n",
    "    df_metrics = pd.DataFrame(metrics).T\n",
    "    print(\"\\n📊 Comparação de Métricas:\")\n",
    "    print(df_metrics.round(4))\n",
    "    \n",
    "    return df_metrics\n",
    "\n",
    "# ===================================================================\n",
    "# EXECUTAR TUDO\n",
    "# ===================================================================\n",
    "\n",
    "print(\"🚀 Iniciando comparação de arquiteturas...\")\n",
    "\n",
    "# Treinar modelos\n",
    "model_simple, model_complex, history_simple, history_complex, X_test_cnn = train_and_compare()\n",
    "\n",
    "# Avaliação final\n",
    "metrics_df = evaluate_models_quick(model_simple, model_complex, X_test_cnn, y_test)\n",
    "\n",
    "print(\"✅ Análise completa!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
